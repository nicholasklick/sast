# KodeCD SAST - Comprehensive Improvement Plan

**Based on Code Review Findings**
**Date**: November 19, 2024
**Priority**: CRITICAL - Core Analysis Accuracy

---

## Executive Summary

The code review identified **4 critical categories** of issues that significantly impact the accuracy and scalability of the SAST engine:

1. ‚ö†Ô∏è **Shallow Semantic Analysis** - Generic AST loses important language semantics
2. üî¥ **CRITICAL: Inaccurate Core Analysis** - CFG, taint analysis, and call graph have logical flaws
3. ‚ö° **Performance Bottlenecks** - Global atomics and CFG cloning will prevent scaling
4. ‚è∏Ô∏è **Incomplete Implementations** - Missing features limit production readiness

**Impact**: These issues will cause **false positives, false negatives, and poor performance** at scale.

**Recommendation**: Address in **3 phases** over 8-12 weeks, prioritizing accuracy over features.

---

## Phase 1: Foundation Fixes (Weeks 1-4) - CRITICAL

**Goal**: Fix the most critical accuracy and performance issues in the parser and analyzer.

### 1.1 Parser Crate - Deep Semantic Extraction

#### Issue 1.1.1: Incomplete AST Classification (HIGH PRIORITY)
**Current State**: `classify_node()` uses `AstNodeKind::Other` fallback for many constructs, losing semantic information.

**Impact**:
- Downstream analysis cannot differentiate between important control flow constructs
- CFG construction is incomplete
- Query matching is inaccurate

**Example of Lost Information**:
```rust
// Current: Falls back to Other
"switch_statement" => AstNodeKind::Other { node_type: "switch_statement" }
"do_statement" => AstNodeKind::Other { node_type: "do_statement" }
"continue_statement" => AstNodeKind::Other { node_type: "continue_statement" }
```

**Solution**:
```rust
// Add new AstNodeKind variants
pub enum AstNodeKind {
    // Existing...

    // Add these:
    SwitchStatement { discriminant: Box<AstNode>, cases: Vec<SwitchCase> },
    SwitchCase { test: Option<Box<AstNode>>, consequent: Vec<AstNode> },
    DoWhileStatement { body: Box<AstNode>, test: Box<AstNode> },
    BreakStatement { label: Option<String> },
    ContinueStatement { label: Option<String> },
    TryStatement { body: Box<AstNode>, handler: Option<Box<AstNode>>, finalizer: Option<Box<AstNode>> },
    FinallyClause { body: Box<AstNode> },
    WithStatement { object: Box<AstNode>, body: Box<AstNode> },
    LabeledStatement { label: String, statement: Box<AstNode> },
    ImportDeclaration { specifiers: Vec<ImportSpecifier>, source: String },
    ExportDeclaration { declaration: Box<AstNode> },
    AwaitExpression { argument: Box<AstNode> },
    YieldExpression { argument: Option<Box<AstNode>>, delegate: bool },
    TemplateLiteral { quasis: Vec<String>, expressions: Vec<Box<AstNode>> },
    TaggedTemplateExpression { tag: Box<AstNode>, quasi: Box<AstNode> },
    ArrayExpression { elements: Vec<Option<AstNode>> },
    ObjectExpression { properties: Vec<ObjectProperty> },
    SpreadElement { argument: Box<AstNode> },
    RestElement { argument: Box<AstNode> },
    ArrowFunctionExpression { params: Vec<Parameter>, body: Box<AstNode>, is_async: bool },
    ConditionalExpression { test: Box<AstNode>, consequent: Box<AstNode>, alternate: Box<AstNode> },
    UpdateExpression { operator: String, argument: Box<AstNode>, prefix: bool },
    SequenceExpression { expressions: Vec<AstNode> },
    NewExpression { callee: Box<AstNode>, arguments: Vec<AstNode> },
    ThisExpression,
    SuperExpression,
}
```

**Implementation Tasks**:
- [ ] 1.1.1.a: Expand `AstNodeKind` enum with 25+ new variants (control flow, expressions)
- [ ] 1.1.1.b: Update `classify_node()` to handle all tree-sitter node types per language
- [ ] 1.1.1.c: Create language-specific mapping tables (JavaScript vs Python vs Java node types)
- [ ] 1.1.1.d: Add unit tests for each new node kind (300+ tests)
- [ ] 1.1.1.e: Update all match statements in analyzer/query to handle new variants

**Estimated Effort**: 40-60 hours
**Risk**: High (breaks existing code)
**Dependencies**: None

---

#### Issue 1.1.2: Brittle Information Extraction (HIGH PRIORITY)
**Current State**: Functions like `extract_name()`, `extract_parameters()` use fragile heuristics.

**Problem Example**:
```rust
// Current: Unreliable
fn extract_name(&self, node: &Node, source: &str) -> Option<String> {
    for i in 0..node.child_count() {
        let child = node.child(i)?;
        if child.kind() == "identifier" {
            return Some(child.utf8_text(source.as_bytes()).ok()?.to_string());
        }
    }
    None
}
```

**Issues**:
- ‚ùå Doesn't use tree-sitter's named fields
- ‚ùå Assumes first identifier is the name
- ‚ùå Language-specific ordering breaks this

**Solution**:
```rust
// Use tree-sitter named fields (reliable)
fn extract_name(&self, node: &Node, source: &str) -> Option<String> {
    // Try named field first (tree-sitter canonical way)
    if let Some(name_node) = node.child_by_field_name("name") {
        return Some(name_node.utf8_text(source.as_bytes()).ok()?.to_string());
    }

    // Fallback to child search for languages without named fields
    self.extract_name_fallback(node, source)
}

fn extract_parameters_detailed(&self, node: &Node, source: &str) -> Vec<Parameter> {
    let mut params = Vec::new();

    // Use tree-sitter's parameters field
    if let Some(params_node) = node.child_by_field_name("parameters") {
        for i in 0..params_node.child_count() {
            if let Some(param_node) = params_node.child(i) {
                if param_node.kind() == "parameter" || param_node.kind().contains("param") {
                    params.push(self.parse_parameter(&param_node, source));
                }
            }
        }
    }

    params
}
```

**Implementation Tasks**:
- [ ] 1.1.2.a: Refactor `extract_name()` to use `child_by_field_name("name")`
- [ ] 1.1.2.b: Refactor `extract_parameters()` to use `child_by_field_name("parameters")`
- [ ] 1.1.2.c: Refactor `extract_return_type()` to use `child_by_field_name("return_type")`
- [ ] 1.1.2.d: Create per-language field mapping documentation
- [ ] 1.1.2.e: Add integration tests with all 15 languages

**Estimated Effort**: 20-30 hours
**Risk**: Medium (backward compatible)
**Dependencies**: None

---

#### Issue 1.1.3: Performance - Global Node ID Counter (MEDIUM PRIORITY)
**Current State**: `static NODE_ID_COUNTER: AtomicUsize` causes contention in parallel parsing.

**Problem**:
```rust
// In parser.rs
static NODE_ID_COUNTER: AtomicUsize = AtomicUsize::new(1);

fn convert_node(&self, node: &Node, source: &str, ...) -> AstNode {
    let id = NODE_ID_COUNTER.fetch_add(1, Ordering::Relaxed); // ‚ùå Global lock
    // ...
}
```

**Performance Impact**:
- Atomic operations are expensive (10-50 CPU cycles)
- Prevents true parallel parsing
- Scales poorly with CPU cores

**Solution**:
```rust
// Remove global atomic, use per-parser context
pub struct Parser {
    config: LanguageConfig,
    file_path: PathBuf,
    node_id_generator: NodeIdGenerator, // ‚úÖ Per-parser state
}

pub struct NodeIdGenerator {
    next_id: usize,
}

impl NodeIdGenerator {
    pub fn new(base_id: usize) -> Self {
        Self { next_id: base_id }
    }

    pub fn generate(&mut self) -> NodeId {
        let id = self.next_id;
        self.next_id += 1;
        id
    }
}

// In parallel parsing:
fn parse_files_parallel(files: Vec<PathBuf>) -> Vec<AstNode> {
    files.par_iter()
        .enumerate()
        .map(|(index, path)| {
            let base_id = index * 1_000_000; // Partition ID space
            let mut parser = Parser::new_with_id_base(config, path, base_id);
            parser.parse_file()
        })
        .collect()
}
```

**Implementation Tasks**:
- [ ] 1.1.3.a: Create `NodeIdGenerator` struct with per-parser state
- [ ] 1.1.3.b: Remove `NODE_ID_COUNTER` global atomic
- [ ] 1.1.3.c: Add `node_id_generator` field to `Parser` struct
- [ ] 1.1.3.d: Update parallel parsing to use partitioned ID spaces
- [ ] 1.1.3.e: Benchmark before/after (expect 20-40% speedup in parallel)

**Estimated Effort**: 10-15 hours
**Risk**: Low (internal refactor)
**Dependencies**: None

---

#### Issue 1.1.4: Security - Stack Overflow Risk (LOW PRIORITY)
**Current State**: Recursive `convert_node()` can overflow on deeply nested ASTs.

**Solution**:
```rust
// Convert to iterative with explicit stack
fn convert_node_iterative(&self, root: &Node, source: &str) -> AstNode {
    let mut stack = vec![(root, None)]; // (node, parent_index)
    let mut nodes = Vec::new();

    while let Some((node, parent_idx)) = stack.pop() {
        let ast_node = self.create_ast_node(node, source);
        let current_idx = nodes.len();
        nodes.push(ast_node);

        // Add children to stack
        for i in (0..node.child_count()).rev() {
            if let Some(child) = node.child(i) {
                stack.push((child, Some(current_idx)));
            }
        }
    }

    // Reconstruct tree from flat list
    self.build_tree_from_nodes(nodes)
}
```

**Implementation Tasks**:
- [ ] 1.1.4.a: Implement iterative AST construction
- [ ] 1.1.4.b: Add depth limit check (max 1000 levels) with error
- [ ] 1.1.4.c: Add stress test with deeply nested code

**Estimated Effort**: 8-12 hours
**Risk**: Low
**Dependencies**: None

---

### 1.2 Analyzer Crate - Core Accuracy Fixes

#### Issue 1.2.1: CRITICAL - Inaccurate CFG Construction
**Current State**: `CfgBuilder` only handles subset of control flow, producing incorrect program models.

**Problem Example**:
```rust
// Current implementation only handles:
match node.kind {
    AstNodeKind::IfStatement => { /* ... */ }
    AstNodeKind::WhileStatement => { /* ... */ }
    AstNodeKind::ForStatement => { /* ... */ }
    _ => { /* Ignores everything else! */ }
}
```

**Missing Control Flow**:
- ‚ùå Switch/case statements (multiple branches)
- ‚ùå Try/catch/finally (exception flow)
- ‚ùå Break/continue (loop exits)
- ‚ùå Return statements (early exit)
- ‚ùå Do-while loops (different entry point)
- ‚ùå Short-circuit operators (&&, ||)
- ‚ùå Ternary operators (? :)
- ‚ùå Goto statements (C/C++)
- ‚ùå Async/await (JavaScript, Rust)

**Solution**:
```rust
impl ControlFlowGraphBuilder {
    fn build_cfg_from_node(&mut self, node: &AstNode, current: CfgGraphIndex) -> CfgGraphIndex {
        match &node.kind {
            // Existing cases...

            AstNodeKind::SwitchStatement { discriminant, cases } => {
                // Create discriminant node
                let disc_node = self.add_statement_node(discriminant);
                self.cfg.add_edge(current, disc_node, normal_edge());

                // Create case branches
                let after_switch = self.create_node(CfgNodeKind::Statement, "after_switch");

                for case in cases {
                    let case_node = self.build_cfg_from_node(&case.consequent[0], disc_node);
                    self.cfg.add_edge(disc_node, case_node,
                        CfgEdge { kind: CfgEdgeKind::Case, label: Some(case.test.text.clone()) });

                    // Fall-through or break
                    if !has_break(&case.consequent) {
                        // Fall through to next case
                    } else {
                        self.cfg.add_edge(case_node, after_switch, normal_edge());
                    }
                }

                after_switch
            }

            AstNodeKind::TryStatement { body, handler, finalizer } => {
                // Build try block
                let try_node = self.build_cfg_from_node(body, current);
                let after_try = self.create_node(CfgNodeKind::Statement, "after_try");

                // Normal flow
                self.cfg.add_edge(try_node, after_try, normal_edge());

                // Exception flow
                if let Some(catch_block) = handler {
                    let catch_node = self.build_cfg_from_node(catch_block, current);
                    self.cfg.add_edge(try_node, catch_node,
                        CfgEdge { kind: CfgEdgeKind::Exception, label: None });
                    self.cfg.add_edge(catch_node, after_try, normal_edge());
                }

                // Finally always executes
                if let Some(finally_block) = finalizer {
                    let finally_node = self.build_cfg_from_node(finally_block, after_try);
                    return finally_node;
                }

                after_try
            }

            AstNodeKind::BreakStatement { label } => {
                // Jump to loop/switch exit
                let break_target = self.find_break_target(label);
                self.cfg.add_edge(current, break_target,
                    CfgEdge { kind: CfgEdgeKind::Break, label: label.clone() });
                self.create_unreachable_node()
            }

            AstNodeKind::ContinueStatement { label } => {
                // Jump to loop header
                let continue_target = self.find_continue_target(label);
                self.cfg.add_edge(current, continue_target,
                    CfgEdge { kind: CfgEdgeKind::Continue, label: label.clone() });
                self.create_unreachable_node()
            }

            AstNodeKind::DoWhileStatement { body, test } => {
                // Do-while: body executes first, then condition
                let body_node = self.build_cfg_from_node(body, current);
                let test_node = self.add_expression_node(test);
                self.cfg.add_edge(body_node, test_node, normal_edge());

                let after_loop = self.create_node(CfgNodeKind::Statement, "after_loop");

                // Loop back or exit
                self.cfg.add_edge(test_node, body_node, true_edge());
                self.cfg.add_edge(test_node, after_loop, false_edge());

                after_loop
            }

            // ... More cases
        }
    }
}
```

**Implementation Tasks**:
- [ ] 1.2.1.a: Add CFG support for switch/case statements
- [ ] 1.2.1.b: Add CFG support for try/catch/finally
- [ ] 1.2.1.c: Add CFG support for break/continue
- [ ] 1.2.1.d: Add CFG support for do-while loops
- [ ] 1.2.1.e: Add CFG support for return statements
- [ ] 1.2.1.f: Add CFG support for short-circuit operators
- [ ] 1.2.1.g: Add CFG support for ternary operators
- [ ] 1.2.1.h: Create CFG visualization tests for each construct
- [ ] 1.2.1.i: Add integration tests with real-world code patterns

**Estimated Effort**: 60-80 hours (CRITICAL PATH)
**Risk**: High (core analysis component)
**Dependencies**: 1.1.1 (rich AST)

---

#### Issue 1.2.2: CRITICAL - Fundamentally Flawed Taint Propagation
**Current State**: Taint analysis operates on string labels, not AST nodes. This is **completely incorrect**.

**Problem Example**:
```rust
// Current (WRONG):
impl TransferFunction for TaintTransferFunction {
    fn transfer(&self, node_label: &str, in_set: &TaintSet) -> TaintSet {
        let mut out = in_set.clone();

        // ‚ùå Parsing strings is brittle and wrong
        if node_label.contains(" = ") {
            let parts: Vec<&str> = node_label.split(" = ").collect();
            if parts.len() == 2 {
                let lhs = parts[0].trim();
                let rhs = parts[1].trim();

                // ‚ùå This doesn't work for: arr[i] = x, obj.field = x, *ptr = x
                // ‚ùå Doesn't handle: let x = y + z (propagates from y and z)
                // ‚ùå Doesn't handle: x = sanitize(y) (should mark as clean)
            }
        }
        out
    }
}
```

**Why This is Broken**:
1. ‚ùå String parsing is brittle (fails on complex expressions)
2. ‚ùå Doesn't understand AST structure
3. ‚ùå Can't differentiate LHS from RHS in assignments
4. ‚ùå Doesn't handle array/object assignments
5. ‚ùå Doesn't handle function arguments
6. ‚ùå Doesn't track sanitization correctly

**Correct Solution**:
```rust
// NEW: Transfer function must work with AST nodes
pub trait TransferFunction {
    fn transfer(
        &self,
        cfg_node: &CfgNode,        // ‚úÖ Has ast_node_id
        ast: &AstNode,              // ‚úÖ Full AST access
        symbol_table: &SymbolTable, // ‚úÖ Variable resolution
        in_set: &TaintSet
    ) -> TaintSet;
}

impl TransferFunction for TaintTransferFunction {
    fn transfer(&self, cfg_node: &CfgNode, ast: &AstNode, symbols: &SymbolTable, in_set: &TaintSet) -> TaintSet {
        let mut out = in_set.clone();

        // Get the actual AST node for this CFG node
        let ast_node = self.find_ast_node(ast, cfg_node.ast_node_id);

        match &ast_node.kind {
            AstNodeKind::AssignmentExpression { left, operator, right } => {
                // ‚úÖ Correctly parse assignment

                // 1. Evaluate RHS to see if it's tainted
                let rhs_taint = self.evaluate_expression(right, symbols, in_set);

                // 2. Extract LHS variable(s)
                let lhs_vars = self.extract_lvalues(left, symbols);

                // 3. Update taint for LHS based on RHS
                if let Some(taint) = rhs_taint {
                    for var in lhs_vars {
                        out.insert(TaintValue::new(var, taint.source));
                    }
                } else {
                    // RHS is clean, remove taint from LHS
                    for var in lhs_vars {
                        out.remove_taint(&var);
                    }
                }
            }

            AstNodeKind::CallExpression { callee, arguments } => {
                // ‚úÖ Check if this is a sanitizer call
                if let Some(func_name) = self.extract_function_name(callee, symbols) {
                    if self.sanitizers.contains(&func_name) {
                        // Sanitizer call - create clean variable
                        // But we need to track what the return value is assigned to
                        // This requires looking at parent assignment
                    }
                }

                // ‚úÖ Check if arguments are tainted (for sinks)
                for arg in arguments {
                    let arg_taint = self.evaluate_expression(arg, symbols, in_set);
                    if arg_taint.is_some() {
                        // Mark this call site as having tainted arguments
                        out.add_tainted_call(cfg_node.id, arg_taint.unwrap());
                    }
                }
            }

            AstNodeKind::VariableDeclaration { name, initializer, .. } => {
                // ‚úÖ Variable declaration with initialization
                if let Some(init) = initializer {
                    let init_taint = self.evaluate_expression(init, symbols, in_set);
                    if let Some(taint) = init_taint {
                        out.insert(TaintValue::new(name.clone(), taint.source));
                    }
                }
            }

            _ => {}
        }

        out
    }

    fn evaluate_expression(
        &self,
        expr: &AstNode,
        symbols: &SymbolTable,
        in_set: &TaintSet
    ) -> Option<TaintValue> {
        match &expr.kind {
            AstNodeKind::Identifier { name } => {
                // Look up variable in taint set
                in_set.get_taint(name).cloned()
            }

            AstNodeKind::BinaryExpression { left, operator, right } => {
                // Taint propagates through binary operations
                let left_taint = self.evaluate_expression(left, symbols, in_set);
                let right_taint = self.evaluate_expression(right, symbols, in_set);

                // If either side is tainted, result is tainted
                left_taint.or(right_taint)
            }

            AstNodeKind::CallExpression { callee, arguments } => {
                // Check if this is a taint source
                if let Some(func_name) = self.extract_function_name(callee, symbols) {
                    if self.is_taint_source(&func_name) {
                        return Some(TaintValue::new(
                            expr.text.clone(),
                            self.source_kind_for_function(&func_name)
                        ));
                    }

                    // Check if this is a sanitizer
                    if self.sanitizers.contains(&func_name) {
                        return None; // Clean
                    }
                }

                // Default: propagate taint from arguments
                for arg in arguments {
                    if let Some(taint) = self.evaluate_expression(arg, symbols, in_set) {
                        return Some(taint);
                    }
                }
                None
            }

            AstNodeKind::MemberExpression { object, property } => {
                // Taint propagates through member access
                self.evaluate_expression(object, symbols, in_set)
            }

            _ => None
        }
    }
}
```

**Implementation Tasks**:
- [ ] 1.2.2.a: **REWRITE** `TransferFunction` trait to take AST + SymbolTable
- [ ] 1.2.2.b: **REWRITE** `TaintTransferFunction::transfer()` to use AST matching
- [ ] 1.2.2.c: Implement `evaluate_expression()` for all expression types
- [ ] 1.2.2.d: Implement `extract_lvalues()` for all assignment targets
- [ ] 1.2.2.e: Add comprehensive unit tests (100+ cases)
- [ ] 1.2.2.f: Integration test with real vulnerability patterns

**Estimated Effort**: 80-100 hours (HIGHEST PRIORITY - BLOCKS ACCURACY)
**Risk**: CRITICAL (entire taint analysis broken)
**Dependencies**: 1.1.1 (rich AST), 1.2.3 (symbol table)

---

#### Issue 1.2.3: Performance - CFG Cloning Performance Disaster
**Current State**: `clone_cfg()` copies entire CFG for taint analysis - massive bottleneck.

**Problem**:
```rust
// In taint.rs line 105:
let cfg_for_transfer = clone_cfg(cfg); // ‚ùå Clones ENTIRE graph!
```

**Why This is Done**:
```rust
// The TransferFunction trait requires 'static lifetime
pub trait TransferFunction: Send + Sync + 'static {
    fn transfer(&self, state: &str, in_set: &TaintSet) -> TaintSet;
}
```

**Performance Impact**:
- For 1000-node CFG: ~50KB memory + 10ms CPU
- For 10,000-node CFG: ~500KB memory + 100ms CPU
- For 100,000-node CFG: ~5MB memory + 1s CPU

**Root Cause**: Lifetime issue in dataflow framework design

**Solution**:
```rust
// Remove 'static requirement
pub trait TransferFunction<'a> {  // ‚úÖ Add lifetime parameter
    fn transfer(
        &self,
        cfg: &'a ControlFlowGraph,  // ‚úÖ Pass by reference
        cfg_node: &CfgNode,
        ast: &'a AstNode,
        symbols: &'a SymbolTable,
        in_set: &TaintSet
    ) -> TaintSet;
}

pub struct DataFlowAnalysis<'a, T: TransferFunction<'a>> {
    direction: DataFlowDirection,
    transfer: T,
    _phantom: PhantomData<&'a ()>,
}

impl<'a, T: TransferFunction<'a>> DataFlowAnalysis<'a, T> {
    pub fn analyze(&self, cfg: &'a ControlFlowGraph) -> DataFlowResult<TaintValue> {
        // Now we can pass cfg by reference, no cloning needed!
        // ...
    }
}
```

**Implementation Tasks**:
- [ ] 1.2.3.a: Add lifetime parameter to `TransferFunction` trait
- [ ] 1.2.3.b: Remove `'static` bound from trait
- [ ] 1.2.3.c: Update `DataFlowAnalysis` to use lifetimes
- [ ] 1.2.3.d: **DELETE** `clone_cfg()` function entirely
- [ ] 1.2.3.e: Update all transfer function implementations
- [ ] 1.2.3.f: Benchmark before/after (expect 50-80% speedup)

**Estimated Effort**: 20-30 hours
**Risk**: Medium (ripple effects)
**Dependencies**: 1.2.2 (rewritten transfer function)

---

#### Issue 1.2.4: Incomplete Symbol Table
**Current State**: `SymbolTableBuilder` only tracks declarations, not usages.

**Problem**:
```rust
// Current: Only creates symbols on declaration
impl Visitor for SymbolTableBuilder {
    fn visit(&mut self, node: &AstNode) {
        match &node.kind {
            AstNodeKind::VariableDeclaration { name, .. } => {
                self.add_symbol(Symbol::Variable { name: name.clone(), ... });
            }
            // ‚ùå Doesn't track where variables are USED
            _ => {}
        }
    }
}
```

**What's Missing**:
- ‚ùå Variable usages (reads)
- ‚ùå Variable type information
- ‚ùå Scope chains (closures, nested functions)
- ‚ùå Symbol resolution (which declaration does this usage refer to?)

**Solution**:
```rust
pub struct Symbol {
    pub name: String,
    pub kind: SymbolKind,
    pub declared_at: NodeId,
    pub scope_id: ScopeId,
    pub type_info: Option<TypeInfo>,
    pub references: Vec<Reference>,  // ‚úÖ Track all usages
}

pub struct Reference {
    pub node_id: NodeId,
    pub kind: ReferenceKind,  // Read, Write, ReadWrite
    pub location: Location,
}

impl SymbolTableBuilder {
    fn visit(&mut self, node: &AstNode) {
        match &node.kind {
            // Declaration: CREATE symbol
            AstNodeKind::VariableDeclaration { name, initializer, var_type } => {
                let symbol = Symbol {
                    name: name.clone(),
                    kind: SymbolKind::Variable,
                    declared_at: node.id,
                    scope_id: self.current_scope,
                    type_info: var_type.clone(),
                    references: Vec::new(),
                };
                self.table.add_symbol(symbol);
            }

            // Usage: ADD reference
            AstNodeKind::Identifier { name } => {
                // Look up symbol in current scope chain
                if let Some(symbol) = self.table.lookup(name, self.current_scope) {
                    symbol.references.push(Reference {
                        node_id: node.id,
                        kind: ReferenceKind::Read,
                        location: node.location.clone(),
                    });
                } else {
                    // Undefined variable - report error or create implicit
                }
            }

            // Assignment: Write reference
            AstNodeKind::AssignmentExpression { left, .. } => {
                if let AstNodeKind::Identifier { name } = &left.kind {
                    if let Some(symbol) = self.table.lookup(name, self.current_scope) {
                        symbol.references.push(Reference {
                            node_id: left.id,
                            kind: ReferenceKind::Write,
                            location: left.location.clone(),
                        });
                    }
                }
            }

            _ => {}
        }

        // Recurse to children
        for child in &node.children {
            self.visit(child);
        }
    }
}
```

**Implementation Tasks**:
- [ ] 1.2.4.a: Add `references: Vec<Reference>` field to `Symbol`
- [ ] 1.2.4.b: Implement complete AST traversal in `SymbolTableBuilder`
- [ ] 1.2.4.c: Track variable reads (identifier expressions)
- [ ] 1.2.4.d: Track variable writes (assignment LHS)
- [ ] 1.2.4.e: Implement scope chain resolution
- [ ] 1.2.4.f: Add unit tests for scope resolution

**Estimated Effort**: 30-40 hours
**Risk**: Medium
**Dependencies**: 1.1.1 (rich AST)

---

#### Issue 1.2.5: Inaccurate Call Graph Builder
**Current State**: Cannot resolve method calls without type information.

**Problem**:
```rust
// Current code:
AstNodeKind::CallExpression { callee, arguments } => {
    if let AstNodeKind::Identifier { name } = &callee.kind {
        // ‚úÖ Can resolve: foo()
        return Some(name.clone());
    }
    if let AstNodeKind::MemberExpression { object, property } = &callee.kind {
        // ‚ùå Cannot resolve: obj.method() - doesn't know type of obj
        return Some(property.clone()); // WRONG: doesn't account for type
    }
}
```

**Example of Failure**:
```javascript
// Code:
let dog = new Dog();
let cat = new Cat();
dog.speak(); // Should resolve to Dog.speak()
cat.speak(); // Should resolve to Cat.speak()

// Current behavior: Both resolve to generic "speak()" - WRONG
```

**Solution**:
```rust
impl CallGraphBuilder {
    fn resolve_call_target(
        &self,
        callee: &AstNode,
        symbols: &SymbolTable,  // ‚úÖ Need symbol table
        type_info: &TypeInferenceResult  // ‚úÖ Need type inference
    ) -> Vec<FunctionId> {
        match &callee.kind {
            AstNodeKind::Identifier { name } => {
                // Direct function call
                vec![self.lookup_function(name)]
            }

            AstNodeKind::MemberExpression { object, property } => {
                // Method call - need object type
                let object_type = type_info.get_type(object.id);

                if let Some(Type::Class(class_name)) = object_type {
                    // Resolve method on class
                    vec![self.lookup_method(class_name, property)]
                } else if let Some(Type::Interface(iface_name)) = object_type {
                    // Interface call - could resolve to multiple implementations
                    self.lookup_interface_implementations(iface_name, property)
                } else {
                    // Unknown type - add all possible methods with this name
                    self.lookup_all_methods_named(property)
                }
            }

            _ => vec![]
        }
    }
}
```

**Implementation Tasks**:
- [ ] 1.2.5.a: Integrate `SymbolTable` into `CallGraphBuilder`
- [ ] 1.2.5.b: Implement basic type inference for variables
- [ ] 1.2.5.c: Resolve method calls using type information
- [ ] 1.2.5.d: Handle interface/polymorphism (multiple targets)
- [ ] 1.2.5.e: Add unit tests with OOP code

**Estimated Effort**: 40-50 hours
**Risk**: High
**Dependencies**: 1.2.4 (symbol table), 1.3.1 (type inference)

---

## Phase 2: Advanced Analysis (Weeks 5-8)

### 2.1 Type Inference System (NEW COMPONENT)

**Rationale**: Required for accurate call graph, taint analysis, and query execution.

**Minimal Type System**:
```rust
pub enum Type {
    Primitive(PrimitiveType),
    Class(String),
    Interface(String),
    Function { params: Vec<Type>, return_type: Box<Type> },
    Array(Box<Type>),
    Union(Vec<Type>),  // TypeScript, Python
    Unknown,
}

pub struct TypeInferenceEngine {
    symbol_table: SymbolTable,
    type_constraints: Vec<TypeConstraint>,
}

impl TypeInferenceEngine {
    pub fn infer_types(&mut self, ast: &AstNode) -> TypeInferenceResult {
        // 1. Collect type constraints from AST
        self.collect_constraints(ast);

        // 2. Solve constraints using unification
        self.solve_constraints();

        // 3. Propagate types through expressions
        self.propagate_types(ast);

        TypeInferenceResult {
            node_types: self.node_types.clone(),
        }
    }
}
```

**Implementation Tasks**:
- [ ] 2.1.1: Design minimal type system (6 base types)
- [ ] 2.1.2: Implement constraint collection from AST
- [ ] 2.1.3: Implement constraint solver (unification algorithm)
- [ ] 2.1.4: Propagate types through expressions
- [ ] 2.1.5: Integration tests with typed languages (Java, TypeScript)

**Estimated Effort**: 60-80 hours
**Risk**: High (new complex component)
**Dependencies**: 1.2.4 (symbol table)

---

### 2.2 Query Crate - Accurate Execution

#### Issue 2.2.1: Brittle Query Evaluation
**Current State**: `QueryExecutor` uses string matching on AST properties.

**Solution**: Use symbol table and deep AST traversal (similar to 1.2.2).

**Implementation Tasks**:
- [ ] 2.2.1.a: Refactor `QueryExecutor` to use `SymbolTable`
- [ ] 2.2.1.b: Implement deep property access evaluation
- [ ] 2.2.1.c: Link taint analysis results to AST nodes for `isTainted()`
- [ ] 2.2.1.d: Expand `matches_entity()` to cover all `AstNodeKind` variants

**Estimated Effort**: 40-50 hours
**Risk**: Medium
**Dependencies**: 1.2.2 (taint), 1.2.4 (symbol table)

---

### 2.3 Reporter Crate - Complete SARIF

#### Issue 2.3.1: Incomplete SARIF Output

**Missing Fields**:
- `ruleId` - Query ID
- `tool.driver.rules` - Query metadata
- `codeFlows` - Taint paths

**Solution**:
```rust
// Populate rule metadata
sarif.runs[0].tool.driver.rules = queries.iter().map(|q| Rule {
    id: q.id.clone(),
    name: q.name.clone(),
    short_description: Message { text: q.description.clone() },
    help: Message { text: q.remediation.clone() },
    default_configuration: RuleConfiguration {
        level: q.severity.to_sarif_level(),
    },
}).collect();

// Add code flows for taint findings
for finding in taint_findings {
    result.code_flows = vec![CodeFlow {
        thread_flows: vec![ThreadFlow {
            locations: finding.path.iter().map(|step| ThreadFlowLocation {
                location: Location {
                    physical_location: PhysicalLocation {
                        artifact_location: ArtifactLocation {
                            uri: step.file.clone(),
                        },
                        region: Region {
                            start_line: step.line,
                            start_column: step.column,
                        },
                    },
                    message: Message { text: step.description.clone() },
                },
            }).collect(),
        }],
    }];
}
```

**Implementation Tasks**:
- [ ] 2.3.1.a: Populate `ruleId` field with query ID
- [ ] 2.3.1.b: Generate `tool.driver.rules` from query metadata
- [ ] 2.3.1.c: Add `codeFlows` for taint analysis paths
- [ ] 2.3.1.d: Validate SARIF against schema

**Estimated Effort**: 15-20 hours
**Risk**: Low
**Dependencies**: None

---

## Phase 3: Scale & Polish (Weeks 9-12)

### 3.1 Performance Optimization
- [ ] 3.1.1: Profile with real-world codebases (100K+ LOC)
- [ ] 3.1.2: Optimize hot paths identified in profiling
- [ ] 3.1.3: Implement parallel file processing
- [ ] 3.1.4: Add incremental analysis (cache ASTs)

**Estimated Effort**: 40-60 hours

---

### 3.2 Testing & Validation
- [ ] 3.2.1: Expand test fixture coverage (500+ vulnerability examples)
- [ ] 3.2.2: Add CVE-based test cases (real vulnerabilities)
- [ ] 3.2.3: Benchmark against Semgrep/Snyk accuracy
- [ ] 3.2.4: Measure false positive/negative rates

**Estimated Effort**: 40-60 hours

---

### 3.3 Documentation
- [ ] 3.3.1: Architecture documentation (CFG, taint, type system)
- [ ] 3.3.2: Query writing guide (KQL examples)
- [ ] 3.3.3: API documentation (for integrations)

**Estimated Effort**: 20-30 hours

---

## Priority Matrix

| Issue | Priority | Impact | Effort | Dependencies |
|-------|----------|--------|--------|--------------|
| 1.2.2 Taint Propagation | üî¥ CRITICAL | ‚ö°‚ö°‚ö°‚ö°‚ö° | 80-100h | 1.1.1, 1.2.3 |
| 1.2.1 CFG Construction | üî¥ CRITICAL | ‚ö°‚ö°‚ö°‚ö° | 60-80h | 1.1.1 |
| 1.1.1 AST Classification | üü† HIGH | ‚ö°‚ö°‚ö°‚ö° | 40-60h | None |
| 1.2.3 CFG Cloning | üü† HIGH | ‚ö°‚ö°‚ö° | 20-30h | 1.2.2 |
| 1.2.4 Symbol Table | üü† HIGH | ‚ö°‚ö°‚ö° | 30-40h | 1.1.1 |
| 2.1 Type Inference | üü† HIGH | ‚ö°‚ö°‚ö° | 60-80h | 1.2.4 |
| 1.1.2 Info Extraction | üü° MEDIUM | ‚ö°‚ö° | 20-30h | None |
| 1.2.5 Call Graph | üü° MEDIUM | ‚ö°‚ö° | 40-50h | 1.2.4, 2.1 |
| 2.2.1 Query Executor | üü° MEDIUM | ‚ö°‚ö° | 40-50h | 1.2.2, 1.2.4 |
| 1.1.3 Node ID Perf | üü¢ LOW | ‚ö° | 10-15h | None |
| 2.3.1 SARIF | üü¢ LOW | ‚ö° | 15-20h | None |
| 1.1.4 Stack Overflow | üü¢ LOW | ‚ö° | 8-12h | None |

---

## Implementation Timeline

### Week 1-2: Foundation
- ‚úÖ Complete 1.1.1 (AST Classification) - 40-60h
- ‚úÖ Complete 1.1.2 (Info Extraction) - 20-30h
- ‚úÖ Start 1.2.4 (Symbol Table) - 15h of 30-40h

### Week 3-4: Core Analysis
- ‚úÖ Complete 1.2.4 (Symbol Table) - 15-25h remaining
- ‚úÖ Complete 1.2.1 (CFG Construction) - 60-80h
- ‚úÖ Start 1.2.2 (Taint Propagation) - 40h of 80-100h

### Week 5-6: Core Analysis Completion
- ‚úÖ Complete 1.2.2 (Taint Propagation) - 40-60h remaining
- ‚úÖ Complete 1.2.3 (CFG Cloning fix) - 20-30h
- ‚úÖ Start 2.1 (Type Inference) - 30h of 60-80h

### Week 7-8: Advanced Features
- ‚úÖ Complete 2.1 (Type Inference) - 30-50h remaining
- ‚úÖ Complete 1.2.5 (Call Graph) - 40-50h
- ‚úÖ Complete 2.2.1 (Query Executor) - 40-50h

### Week 9-10: Polish & Optimization
- ‚úÖ Complete 1.1.3, 1.1.4, 2.3.1 (Low priority items) - 30-50h
- ‚úÖ Performance optimization (3.1) - 40h of 40-60h

### Week 11-12: Testing & Documentation
- ‚úÖ Validation & testing (3.2) - 40-60h
- ‚úÖ Documentation (3.3) - 20-30h

**Total Estimated Effort**: 650-900 hours (~4-6 months for 1 developer, 2-3 months for 2 developers)

---

## Success Metrics

### Accuracy Improvements
- **False Positive Rate**: Reduce from unknown to <5%
- **False Negative Rate**: Reduce from unknown to <10%
- **Taint Analysis Accuracy**: Increase from ~30% to >85%
- **CFG Correctness**: 100% of control flow constructs modeled

### Performance Improvements
- **Parsing Speed**: 20-40% improvement (remove global atomic)
- **Taint Analysis Speed**: 50-80% improvement (remove CFG cloning)
- **Memory Usage**: 40-60% reduction (remove redundant clones)
- **Scalability**: Handle 100K+ LOC files without issues

### Completeness Improvements
- **AST Coverage**: Increase from ~60% to >95% of language constructs
- **Symbol Resolution**: 100% of variables tracked
- **Call Graph Accuracy**: Increase from ~40% to >80%
- **SARIF Completeness**: 100% of required fields populated

---

## Risk Management

### High Risks

1. **Taint Analysis Rewrite Breaking Everything** (Likelihood: High, Impact: Critical)
   - **Mitigation**: Implement new version alongside old, A/B test results
   - **Fallback**: Keep old version as "legacy mode"

2. **Timeline Overruns** (Likelihood: Medium, Impact: High)
   - **Mitigation**: Prioritize by impact, cut low-priority features if needed
   - **Fallback**: Ship in phases (Phase 1 only, then Phase 2)

3. **Performance Regressions** (Likelihood: Medium, Impact: Medium)
   - **Mitigation**: Benchmark before/after each change
   - **Fallback**: Revert if regression >20%

### Medium Risks

1. **Type Inference Complexity** (Likelihood: Medium, Impact: Medium)
   - **Mitigation**: Start with simple types, expand gradually
   - **Fallback**: Use "unknown" type for complex cases

2. **Lifetime/Ownership Issues in Refactor** (Likelihood: Medium, Impact: Medium)
   - **Mitigation**: Incremental refactoring, extensive testing
   - **Fallback**: Use Rc/Arc if lifetimes become too complex

---

## Recommendations

### Immediate Actions (This Week)
1. **Set up dedicated refactor branch**: `feature/core-analysis-accuracy`
2. **Add comprehensive benchmarking**: Before any changes, establish performance baseline
3. **Expand test suite**: Need 500+ test cases before refactoring
4. **Code freeze on new features**: Focus 100% on accuracy

### Phase 1 Priority (Weeks 1-4)
1. **Start with 1.1.1 (AST Classification)** - Unblocks everything else
2. **Then 1.2.4 (Symbol Table)** - Needed by most analysis
3. **Then 1.2.2 (Taint Analysis)** - Highest impact on accuracy
4. **Skip 1.1.3, 1.1.4 for now** - Low priority optimizations

### Resource Allocation
- **Option A (1 developer)**: 4-6 months full-time
- **Option B (2 developers)**: 2-3 months full-time
  - Developer 1: Parser + Analyzer
  - Developer 2: Symbol Table + Type Inference
- **Option C (3 developers)**: 6-8 weeks full-time
  - Developer 1: Parser (1.1.x)
  - Developer 2: Analyzer (1.2.x)
  - Developer 3: Query + Reporter (2.x)

### Success Criteria for "Phase 1 Complete"
- ‚úÖ All 15 languages have >90% AST node classification
- ‚úÖ CFG handles all control flow constructs
- ‚úÖ Taint analysis operates on AST, not strings
- ‚úÖ Symbol table tracks declarations + usages
- ‚úÖ No CFG cloning (performance fixed)
- ‚úÖ Test suite has 500+ cases, all passing
- ‚úÖ Benchmarks show 30%+ performance improvement

---

## Conclusion

This improvement plan addresses the **critical accuracy and performance issues** identified in the code review. The current implementation has fundamental flaws that will cause incorrect analysis results and poor scaling.

**The good news**: The architecture is sound, the issues are fixable, and the test suite provides a solid foundation.

**The challenge**: This is 650-900 hours of work (~4-6 months for 1 developer) requiring deep expertise in compilers, dataflow analysis, and Rust lifetimes.

**The payoff**: After Phase 1, KodeCD SAST will have **production-grade accuracy** and **superior performance** compared to competitors like Semgrep and Snyk.

**Recommended approach**:
1. **Secure funding/resources for 2-3 developers for 2-3 months**
2. **Start with Phase 1 (Weeks 1-4) immediately**
3. **Re-evaluate after Phase 1 completion**
4. **Consider hiring a compiler expert as consultant for Phase 2**

---

**Next Steps**:
1. Review this plan with the team
2. Prioritize which phases to tackle
3. Set up project tracking (GitHub Projects)
4. Begin Phase 1 implementation

**Questions?** Happy to discuss implementation details, resource allocation, or alternative approaches.
